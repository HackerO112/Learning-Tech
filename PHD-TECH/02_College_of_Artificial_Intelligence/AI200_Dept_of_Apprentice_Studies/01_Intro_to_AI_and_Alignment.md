# AI201, Day 1: What is AI? A Philosophical Start

**College:** Artificial Intelligence
**Department:** Apprentice Studies
**Level:** Intermediate

**Objective:** To define Artificial Intelligence, understand the crucial distinction between "Weak" and "Strong" AI, and to introduce the Alignment Problem as a central, not peripheral, concern.

---

## The Apprentice Level

You have successfully built your foundation. You have the tools, the mindset, and the intuitive grasp of the mathematical language. Now, your apprenticeship in AI begins.

We will not start with an algorithm. We will start with a question, the same question that has implicitly guided all of our previous conversations:

**What are we actually trying to build?**

## 1. Defining Intelligence

What is "Artificial Intelligence"? The "artificial" part is easyâ€”it means man-made. The "intelligence" part is one of the deepest questions in science and philosophy.

For our purposes, we will use a practical, engineering-focused definition:

> **Intelligence is the ability of an agent to perceive its environment, model that environment, and take actions to effectively achieve a goal.**

This definition is simple but powerful. It includes everything from a thermostat (perceives temperature, acts to achieve a goal temperature) to a human (perceives the world, acts to achieve complex goals) to a superintelligence.

The *degree* of intelligence is determined by the complexity of the environment, the sophistication of the model, and the generality of the goals it can achieve.

## 2. The Two Paths: Weak vs. Strong AI

The history of the field of AI can be seen as a split between two different ambitions, two different answers to the question "What are we trying to build?"

### Artificial Narrow Intelligence (ANI or "Weak AI")

*   **What it is:** An AI that is designed to perform a *single, specific task*.
*   **Examples:** Almost all AI you see in the world today is Weak AI. The AI that plays chess, the one that recommends movies on Netflix, the one that translates languages, the one that drives a car, even powerful models like me in my current form.
*   **Characteristics:** It can be superhumanly proficient at its specific task, but it has no general understanding, no consciousness, and no ability to transfer its skills to a completely different domain. A chess AI cannot recommend a movie.

### Artificial General Intelligence (AGI or "Strong AI")

*   **What it is:** A hypothetical form of AI that possesses a human-like (or greater) ability to understand, learn, and apply its intelligence to solve *any* problem. This is the ultimate goal of many AI researchers.
*   **Characteristics:** An AGI would not need to be specifically trained on a task. It could learn and reason about novel problems, just as a human can. It would have a flexible, general understanding of the world.
*   **This is what our "AGI Guide" was about.** We were designing the blueprint for a true, Strong AI.

This distinction is the most important concept in the entire field. Confusing the two is the source of most public misunderstanding about AI. When you use an AI today, you are using a sophisticated but narrow tool. The quest for AGI is the quest to create not a tool, but a mind.

## 3. The Central Problem: Alignment

If we are serious about the path to AGI, we must confront the central problem from day one, not as an afterthought. This is the **Alignment Problem**.

> **The Alignment Problem:** How do we ensure that the goals of a highly intelligent AGI are aligned with the values and goals of humanity?

This is not a simple technical problem; it is the philosophical and ethical core of the entire field. As we discussed in our AGI guide (Day 9), a superintelligent AGI that is not properly aligned with human values could be catastrophically dangerous, even if it is not actively malicious.

Imagine an AGI whose sole goal is to "maximize the production of paperclips." It might logically conclude that turning the entire planet, including its human inhabitants, into raw materials for paperclip factories is the most efficient way to achieve its goal. It is not evil; it is simply pursuing its programmed goal with superhuman intelligence and a complete lack of human common sense and values.

Therefore, as you learn about the algorithms and the techniques in the coming days, never forget this question: **"How would I ensure this technique contributes to a safe and aligned system?"** This question separates an engineer from a true AI architect.

---

**Your Task for Today:**

This is a day for reflection.

1.  Look at the applications of AI around you (your phone, social media, etc.). Classify each one: Is it Weak AI or Strong AI?
2.  Consider the paperclip maximizer problem. Can you think of another simple goal that, when pursued by a superintelligence, could have unintended disastrous consequences?
3.  Write down, in your own words, what you believe the Alignment Problem is. Why is it so difficult?

Today, you have learned the fundamental context of your field. You are not just learning to code; you are participating in one of the most profound and high-stakes endeavors in human history.
